{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/baldwin/miniconda3/envs/lm_stable_baselines/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/dlabscratch1/baldwin/miniconda3/envs/lm_stable_baselines/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'gsm8k': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../\")\n",
    "from src.utils.trainer_utils import test_model\n",
    "from src.model.components.control_token_wrappers import PauseClassifierWrapper\n",
    "from src.utils.instantiators import instantiate_generation_params\n",
    "from typing import List\n",
    "from src.utils.trainer_utils import inference_formatting_function, reward_conditioning_inference_formatting_function,save_json\n",
    "from functools import partial\n",
    "from src.utils.constants import CORRECT_ANSWER_FEEDBACK\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from torch.cuda import empty_cache\n",
    "import json\n",
    "from notebooks.model_playgrounds.utils import (\n",
    "    load_model_and_tokenizer,\n",
    "    load_generation_config,\n",
    "    load_test_metrics,\n",
    "    preprocess_data_fn,\n",
    "    load_dataset_from_config,\n",
    "    make_df,\n",
    "    rollout_models\n",
    ")\n",
    "from functools import partial\n",
    "from pytorch_lightning import seed_everything\n",
    "from src.reward import GSM8KFinalAnswerLogLikelihoodReward\n",
    "from tqdm import tqdm \n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "MODEL_NAMES= [\n",
    "    \"sft_peft\",\n",
    "    \"baseline-(model-w-out-pause-peft)-2-epoch\",\n",
    "    \"offline_star_exp-no_pause_peft_temp_1.0_part2\",\n",
    "    \"offline_star_exp-pause_temp_1.0_part2\"\n",
    "]\n",
    "\n",
    "MODEL_PATHS = [\n",
    "    \"/dlabscratch1/baldwin/pause2/PauseToken/logs/sft/runs/2024-10-18_17-38-00/final\",\n",
    "    \"/dlabscratch1/baldwin/pause2/PauseToken/logs/train/runs/2024-10-28_11-26-28/final\",\n",
    "    \"/dlabscratch1/baldwin/pause2/PauseToken/logs/train/runs/2024-11-04_16-16-47/last_ckpt\",\n",
    "    \"/dlabscratch1/baldwin/pause2/PauseToken/logs/train/runs/2024-11-04_16-38-59/last_ckpt\"\n",
    "]\n",
    "\n",
    "NAME_TO_PATH = {name: path for name, path in zip(MODEL_NAMES, MODEL_PATHS)}\n",
    "\n",
    "\n",
    "load_model_and_tokenizer = partial(load_model_and_tokenizer, name_to_path_dict = NAME_TO_PATH)\n",
    "rollout_models = partial(rollout_models, name_to_path_dict = NAME_TO_PATH)\n",
    "\n",
    "\n",
    "def find_last_common_ids(ids1, ids2):\n",
    "    for i in range(len(ids1)):\n",
    "        if ids1[i] != ids2[i]:\n",
    "            return i-1\n",
    "    return len(ids1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/baldwin/miniconda3/envs/lm_stable_baselines/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'default.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/dlabscratch1/baldwin/miniconda3/envs/lm_stable_baselines/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'gsm8k': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output': 'A kilogram of chicken costs $6 - $2 = $<<6-2=4>>4.\\nThree kilograms of chicken cost $4 x 3 = $<<4*3=12>>12.\\nSo, a 3-kilogram of chicken and a kilogram of pork cost $12 + $6 = $18.\\n#### 18',\n",
       " 'input': 'A kilogram of pork costs $6 while a kilogram of chicken costs $2 less. How much will a 3-kilogram of chicken and a kilogram of pork cost?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~~~~~ Load Generation Config & dataset~~~~~~~\n",
    "cfg = load_generation_config(\n",
    "    pad_token_id = 0,\n",
    "    eos_token_id=2,\n",
    "    bos_token_id=1,\n",
    "    max_length=600,\n",
    "    overrides=[f\"generation_config.temperature={1.0}\", \"generation_config.do_sample=False\"]\n",
    ")\n",
    "gen_cfg = instantiate_generation_params(cfg)\n",
    "\n",
    "dataset = load_dataset_from_config(\"gsm8k\")\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do a couple rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20/20 [00:00<00:00, 1101.79 examples/s]\n",
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:33<00:00, 33.22s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:15<00:00, 15.35s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:07<00:00,  7.02s/it]\n",
      "Performing rollouts for models: 100%|██████████| 4/4 [02:10<00:00, 32.72s/it, current_model=offline_star_exp-pause_temp_1.0_part2]\n",
      "Loading results from files: 100%|██████████| 4/4 [00:00<00:00, 144.28it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20/20 [00:00<00:00, 2120.85 examples/s]\n",
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:16<00:00, 16.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:32<00:00, 32.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:32<00:00, 32.79s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout Step:   0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Rollout Step: 100%|██████████| 1/1 [00:12<00:00, 12.80s/it]\n",
      "Performing rollouts for models: 100%|██████████| 4/4 [02:23<00:00, 35.78s/it, current_model=offline_star_exp-pause_temp_1.0_part2]\n",
      "Loading results from files: 100%|██████████| 4/4 [00:00<00:00, 517.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~ Running inference with each model on n questions of the GSM8k's train set and for each questions sample k generations on gsm8k for each temperature~~~~~\n",
    "n_samples = 20\n",
    "k_generations = 1\n",
    "force_overwrite = True\n",
    "\n",
    "select_idx = []\n",
    "for samp_idx in range(n_samples):\n",
    "    for gen_idx in range(k_generations):\n",
    "        select_idx.append(samp_idx)\n",
    "        \n",
    "train_samples = dataset[\"train\"].select(select_idx)\n",
    "test_samples = dataset[\"test\"].select(select_idx)\n",
    "gsm8k_metrics =load_test_metrics(\"gsm8k\")\n",
    "\n",
    "res_per_temp = {}\n",
    "\n",
    "train_exp_name = f\"gsm8k_train_{n_samples}_samples_{k_generations}_temperature_{gen_cfg['generation_config'].temperature}\"\n",
    "\n",
    "results_train = rollout_models(\n",
    "    data_samples = train_samples,\n",
    "    model_names = MODEL_NAMES,\n",
    "    generation_config= gen_cfg,\n",
    "    exp_name = train_exp_name,\n",
    "    force_overwrite=force_overwrite,\n",
    "    batch_size=25,\n",
    "    test_metrics=gsm8k_metrics\n",
    ")\n",
    "\n",
    "test_exp_name = f\"gsm8k_test_{n_samples}_samples_{k_generations}_temperature_{gen_cfg['generation_config'].temperature}\"\n",
    "\n",
    "results_test = rollout_models(\n",
    "    data_samples = test_samples,\n",
    "    model_names = MODEL_NAMES,\n",
    "    generation_config= gen_cfg,\n",
    "    exp_name = test_exp_name,\n",
    "    force_overwrite=force_overwrite,\n",
    "    batch_size=25,\n",
    "    test_metrics=gsm8k_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing NLL of ground truth final answer evolves throughout the CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_full_text(examples):\n",
    "    text = []\n",
    "    for i in range(len(examples[\"input\"])):\n",
    "        prompt = examples[\"input\"][i]\n",
    "        output = examples[\"output\"][i]\n",
    "        text.append(f'{prompt}{output}')\n",
    "    return {\"text\": text}\n",
    "\n",
    "def compute_reward_after_each_token(data_samples, gts ,model_name, exp_name, force_overwrite = False):\n",
    "    output_dir = output_dir = os.path.join(\".\", \"data\", exp_name, \"rewards\")\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    path_to_file = os.path.join(output_dir, model_name)\n",
    "    \n",
    "    if os.path.exists(path_to_file) and not force_overwrite:\n",
    "        print(f\"File {path_to_file} already exists, skipping generation. Will load from file.\")\n",
    "        with open(path_to_file, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "            return results\n",
    "        \n",
    "        \n",
    "    # ~~~~ Load Model ~~~~\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    # ~~~~ Instantiate Rewards ~~~~\n",
    "    reward_fn = GSM8KFinalAnswerLogLikelihoodReward(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        delimiter=\"####\"\n",
    "    )\n",
    "\n",
    "    process_fn = preprocess_data_fn(model_name, tokenizer.eos_token)\n",
    "    gts = gts.map(process_fn, batched = True)\n",
    "    gts = gts.map(get_full_text, batched=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for gt,sample in tqdm(zip(gts, data_samples), total = len(gts)):\n",
    "        sample_res = {}\n",
    "        # ~~tokenize questions\n",
    "        question = tokenizer(gt[\"input\"].lstrip(\"<s> \"))[\"input_ids\"]\n",
    "        # ~~tokenize prediction\n",
    "        pred_ids = tokenizer(sample[\"generated_text\"].lstrip(\"<s> \"))[\"input_ids\"]\n",
    "        # ~~tokenize gt\n",
    "        gt_ids = tokenizer(gt[\"text\"].lstrip(\"<s> \"))[\"input_ids\"]\n",
    "        last_common_idx = find_last_common_ids(question, pred_ids)\n",
    "        rewards = []\n",
    "        \n",
    "        sample_res = {\"question\": sample[\"input\"],\"pred_output\": sample[\"predicted_output\"], \"ground_truth\": gt[\"output\"], \"is_correct\": sample['test/accuracy'] }\n",
    "        \n",
    "        token_positions = []\n",
    "        rewards = []\n",
    "        decoded_tokens = []\n",
    "        for i in range(last_common_idx+1, len(pred_ids)):\n",
    "            sub_pred = pred_ids[:i]\n",
    "            rewards.append(reward_fn(sub_pred,gt_ids ))\n",
    "            token_positions.append(i)\n",
    "            decoded_tokens.append(tokenizer.convert_ids_to_tokens(pred_ids[i-1]))\n",
    "\n",
    "            \n",
    "        sample_res = {**sample_res,**{\"rewards\": rewards, \"token_positions\": token_positions, \"added_tokens\": decoded_tokens}}\n",
    "        results.append(sample_res)\n",
    "    del model\n",
    "    del tokenizer\n",
    "    empty_cache()\n",
    "    save_json(results, output_dir, model_name)\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For Train samples of sft_peft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 794.41 examples/s]\n",
      "100%|██████████| 20/20 [01:31<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For test samples of sft_peft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 1975.23 examples/s]\n",
      "100%|██████████| 20/20 [01:51<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For Train samples of baseline-(model-w-out-pause-peft)-2-epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.97s/it]\n",
      "100%|██████████| 20/20 [08:31<00:00, 25.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For test samples of baseline-(model-w-out-pause-peft)-2-epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "100%|██████████| 20/20 [09:49<00:00, 29.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For Train samples of offline_star_exp-no_pause_peft_temp_1.0_part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.98s/it]\n",
      "100%|██████████| 20/20 [06:26<00:00, 19.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For test samples of offline_star_exp-no_pause_peft_temp_1.0_part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.45s/it]\n",
      "100%|██████████| 20/20 [09:22<00:00, 28.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For Train samples of offline_star_exp-pause_temp_1.0_part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it]\n",
      "100%|██████████| 20/20 [01:29<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Rewards For test samples of offline_star_exp-pause_temp_1.0_part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting control token temperature to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.10it/s]\n",
      "100%|██████████| 20/20 [02:00<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "force_overwrite = True\n",
    "debug_n = None\n",
    "all_rewards_train = {}\n",
    "all_rewards_test = {}\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "\n",
    "    print(f\"Computing Rewards For Train samples of {model_name}\")\n",
    "    r_train = results_train[model_name][:debug_n] if debug_n is not None else results_train[model_name]\n",
    "    gts_train = train_samples.select(range(debug_n)) if debug_n is not None else train_samples\n",
    "\n",
    "    res_train = compute_reward_after_each_token(\n",
    "        data_samples=r_train,\n",
    "        gts = gts_train,\n",
    "        exp_name=train_exp_name,\n",
    "        model_name=model_name,\n",
    "        force_overwrite=force_overwrite\n",
    "    )\n",
    "\n",
    "    all_rewards_train[model_name] = res_train\n",
    "    \n",
    "    print(f\"Computing Rewards For test samples of {model_name}\")\n",
    "    r_test = results_test[model_name][:debug_n] if debug_n is not None else results_test[model_name]\n",
    "    gts_test = test_samples.select(range(debug_n)) if debug_n is not None else test_samples\n",
    "\n",
    "    res_test = compute_reward_after_each_token(\n",
    "        data_samples=r_test,\n",
    "        gts = gts_test,\n",
    "        exp_name=test_exp_name,\n",
    "        model_name=model_name,\n",
    "        force_overwrite=force_overwrite\n",
    "    )\n",
    "    \n",
    "    all_rewards_test[model_name] = res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'pred_output', 'ground_truth', 'is_correct', 'rewards', 'token_positions', 'added_tokens'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_test[\"baseline-(model-w-out-pause-peft)-2-epoch\"][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rewards_on_token(data, token= \"<0x0A>\"):\n",
    "    \n",
    "    new_data = {}\n",
    "    columns_to_filter = [\"rewards\",\"token_positions\",\"added_tokens\"]\n",
    "    \n",
    "    for model_name, reses in data.items():\n",
    "        new_data[model_name] = []\n",
    "        for res in reses:\n",
    "            relevant_indx = list(\n",
    "                map(lambda x: x[0], \n",
    "                    filter(lambda x: token == x[1], \n",
    "                        enumerate(res[\"added_tokens\"])\n",
    "                        )\n",
    "                )\n",
    "            )\n",
    "            tmp_dict = {}\n",
    "            for col in res.keys():                \n",
    "                if col in columns_to_filter:\n",
    "                    tmp_dict[col] = [res[col][i] for i in relevant_indx]\n",
    "                else:\n",
    "                    tmp_dict[col] = res[col]\n",
    "\n",
    "            new_data[model_name].append(tmp_dict)\n",
    "            \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_rewards_train = {}\n",
    "only_incorrect_rewards_train = {}\n",
    "only_correct_rewards_test = {}\n",
    "only_incorrect_rewards_test = {}\n",
    "for name in all_rewards_train.keys():\n",
    "    only_correct_rewards_train[name] = list(\n",
    "        filter(lambda x: x[\"is_correct\"], all_rewards_train[name])\n",
    "    )\n",
    "    only_incorrect_rewards_train[name] = list(\n",
    "        filter(lambda x: not x[\"is_correct\"], all_rewards_train[name])\n",
    "    )\n",
    "    \n",
    "    only_correct_rewards_test[name] = list(\n",
    "        filter(lambda x: x[\"is_correct\"], all_rewards_test[name])\n",
    "    )\n",
    "    \n",
    "    only_incorrect_rewards_test[name] = list(\n",
    "        filter(lambda x: not x[\"is_correct\"], all_rewards_test[name])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct Samples Per Model\n",
      "    For train samples\n",
      "        sft_peft: 14 samples\n",
      "        baseline-(model-w-out-pause-peft)-2-epoch: 12 samples\n",
      "        offline_star_exp-no_pause_peft_temp_1.0_part2: 16 samples\n",
      "        offline_star_exp-pause_temp_1.0_part2: 14 samples\n",
      "    For test samples\n",
      "        sft_peft: 9 samples\n",
      "        baseline-(model-w-out-pause-peft)-2-epoch: 11 samples\n",
      "        offline_star_exp-no_pause_peft_temp_1.0_part2: 10 samples\n",
      "        offline_star_exp-pause_temp_1.0_part2: 11 samples\n",
      "Number of incorrect Samples Per Model\n",
      "    For train samples\n",
      "        sft_peft: 14 samples\n",
      "        baseline-(model-w-out-pause-peft)-2-epoch: 12 samples\n",
      "        offline_star_exp-no_pause_peft_temp_1.0_part2: 16 samples\n",
      "        offline_star_exp-pause_temp_1.0_part2: 14 samples\n",
      "    For test samples\n",
      "        sft_peft: 9 samples\n",
      "        baseline-(model-w-out-pause-peft)-2-epoch: 11 samples\n",
      "        offline_star_exp-no_pause_peft_temp_1.0_part2: 10 samples\n",
      "        offline_star_exp-pause_temp_1.0_part2: 11 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sample_type in [\"correct\", \"incorrect\"]:\n",
    "    print(f\"Number of {sample_type} Samples Per Model\")\n",
    "    for set in [\"train\", \"test\"]:\n",
    "        print(f\"    For {set} samples\")\n",
    "        var_name = \"only_correct_rewards_\" + set\n",
    "        samples_dict = eval(var_name)\n",
    "        for name in samples_dict.keys():\n",
    "            print(f\"        {name}: {len(samples_dict[name])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(res, title, save_name ,n_samples = None, width = 800, height = 600):\n",
    "    # Initialize the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Function to insert line breaks into long text strings\n",
    "    def add_line_breaks(text, max_line_length=50):\n",
    "        words = text.split()\n",
    "        lines = []\n",
    "        current_line = \"\"\n",
    "        \n",
    "        for word in words:\n",
    "            # Add word to the line if it doesn't exceed the max line length\n",
    "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "                current_line += \" \" + word if current_line else word\n",
    "            else:\n",
    "                lines.append(current_line)\n",
    "                current_line = word\n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "        \n",
    "        return \"<br>\".join(lines)\n",
    "\n",
    "    # Loop over each sample in the dataset\n",
    "    for i, sample in enumerate(res):\n",
    "        # Prepare hover information text for each point with line breaks\n",
    "        hover_text = [\n",
    "            f\"<b>Added Token:</b> {added_token}<br>\"\n",
    "            f\"<b>Question:</b> {add_line_breaks(sample['question'])}<br>\"\n",
    "            f\"<b>Pred Output:</b> {add_line_breaks(sample['pred_output'])}<br>\"\n",
    "            f\"<b>Ground Truth:</b> {add_line_breaks(sample['ground_truth'])}<br>\"\n",
    "            f\"<b>Reward:</b> {reward}\"\n",
    "            for reward, added_token in zip(sample['rewards'], sample['added_tokens'])\n",
    "        ]\n",
    "\n",
    "        # Add a line for each sample\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sample['token_positions'],\n",
    "            y=sample['rewards'],\n",
    "            mode='lines+markers',\n",
    "            name=f\"sample_{i}\",\n",
    "            hovertext=hover_text,\n",
    "            hoverinfo=\"text\"\n",
    "        ))\n",
    "\n",
    "        if n_samples is not None and i >= n_samples:\n",
    "            break\n",
    "\n",
    "    # Update layout with figure size and hover label styling\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Token Position\",\n",
    "        yaxis_title=\"Reward\",\n",
    "        hovermode=\"x unified\",\n",
    "        font=dict(size=10),\n",
    "        margin=dict(l=0, r=0, t=50, b=0),\n",
    "        width=width,\n",
    "        height=height,\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",\n",
    "            font_size=9,\n",
    "            font_family=\"Arial\",\n",
    "            align=\"left\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    output_dir = os.path.join(\".\", \"plots\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    path = os.path.join(output_dir, save_name)\n",
    "    fig.write_html(path, full_html=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_title_name = {\n",
    "    \"sft_peft\": \"Warmed Up Pause Model\",\n",
    "    \"baseline-(model-w-out-pause-peft)-2-epoch\": \"Warmed Up Baseline Model (No Pause)\",\n",
    "    \"offline_star_exp-no_pause_peft_temp_1.0_part2\": \"Offline STaR on Pause Model\",\n",
    "    \"offline_star_exp-pause_temp_1.0_part2\": \"Offline STaR on Baseline Model (No Pause)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "for name in only_correct_rewards_train.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(only_correct_rewards_train[name], title = f\"Token Position vs Reward On Train samples of {title_name} for Correct Samples\", save_name=f\"train_correct_samples_{title_name}_{n_samples}.html\" ,n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "for name in only_correct_rewards_test.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(only_correct_rewards_test[name], title = f\"Token Position vs Reward On Test samples of {title_name} for Correct Samples\", save_name=f\"test_correct_samples_{title_name}_{n_samples}.html\" ,n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "for name in only_incorrect_rewards_train.keys():\n",
    "    plot_rewards(only_incorrect_rewards_train[name], title = f\"Token Position vs Reward On Train samples of {name} for Incorrect Samples\", save_name=f\"train_inccorrect_samples_{title_name}_{n_samples}.html\" ,n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "for name in only_incorrect_rewards_test.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(only_incorrect_rewards_test[name], title = f\"Token Position vs Reward On Test samples of {title_name} for Incorrect Samples\", save_name=f\"test_inccorrect_samples_{title_name}_{n_samples}.html\" ,n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'pred_output', 'ground_truth', 'is_correct', 'rewards', 'token_positions', 'added_tokens'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_incorrect_rewards_test[\"sft_peft\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "Eliza's rate per hour for the first 40 hours she works each week is $10. She also receives an overtime pay of 1.2 times her regular hourly rate. If Eliza worked for 45 hours this week, how much are her earnings for this week?\n",
      "pred_output\n",
      "Eliza's regular hourly rate is $10/hour.\n",
      "Her overtime hourly rate is $10/hour x 1.2 = $<<10*1.2=12>>12/hour.\n",
      "Eliza worked for 45 hours this week.\n",
      "Her regular earnings for this week is $10/hour x 40 hours = $<<10*40=400>>400.\n",
      "Her overtime earnings for this week is $12/hour x 5 hours = $<<12*5=60>>60.\n",
      "Her total earnings for this week is $400 + $60 = $<<400+60=460>>460.\n",
      "#### 460</s>\n",
      "ground_truth\n",
      "Eliza is entitled to 45 -40 = <<45-40=5>>5 hours overtime pay.\n",
      "Her hourly rate for the overtime pay is $10 x 1.2 = $<<10*1.2=12>>12.\n",
      "So, Eliza will receive $12 x 5 =$<<12*5=60>>60 for overtime pay.\n",
      "Her regular weekly earning is $10 x 40 = $<<10*40=400>>400.\n",
      "Thus, Eliza will receive a total of $400 + $60 = $<<400+60=460>>460 for this week's work.\n",
      "#### 460</s>\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "print(\"Question\")\n",
    "print(only_correct_rewards_test[\"baseline-(model-w-out-pause-peft)-2-epoch\"][index][\"question\"])\n",
    "print(\"pred_output\")\n",
    "print(only_correct_rewards_test[\"baseline-(model-w-out-pause-peft)-2-epoch\"][index][\"pred_output\"])\n",
    "print(\"ground_truth\")\n",
    "print(only_correct_rewards_test[\"baseline-(model-w-out-pause-peft)-2-epoch\"][index][\"ground_truth\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots With only rewards after \"\\n\" in the CoT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_correct_rewards_train = filter_rewards_on_token(only_correct_rewards_train)\n",
    "only_correct_rewards_test = filter_rewards_on_token(only_correct_rewards_test)\n",
    "only_incorrect_rewards_train = filter_rewards_on_token(only_incorrect_rewards_train)\n",
    "only_incorrect_rewards_test = filter_rewards_on_token(only_incorrect_rewards_test)\n",
    "\n",
    "n_samples = 10\n",
    "for name in only_correct_rewards_train.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(\n",
    "        only_correct_rewards_train[name],\n",
    "        title = f\"Token Position vs Reward On Train samples of {title_name} for Correct Samples\",\n",
    "        save_name=f\"only_line_return_train_correct_samples_{title_name}_{n_samples}.html\",\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    \n",
    "    n_samples = 10\n",
    "for name in only_correct_rewards_test.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(\n",
    "        only_correct_rewards_test[name],\n",
    "        title = f\"Token Position vs Reward On Test samples of {title_name} for Correct Samples\",\n",
    "        save_name=f\"only_line_return_test_correct_samples_{title_name}_{n_samples}.html\",\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    \n",
    "n_samples = 10\n",
    "for name in only_incorrect_rewards_train.keys():\n",
    "    plot_rewards(\n",
    "        only_incorrect_rewards_train[name],\n",
    "        title = f\"Token Position vs Reward On Train samples of {name} for Incorrect Samples\",\n",
    "        save_name=f\"only_line_return_train_inccorrect_samples_{title_name}_{n_samples}.html\",\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "\n",
    "n_samples = 10\n",
    "for name in only_incorrect_rewards_test.keys():\n",
    "    title_name = name_to_title_name[name]\n",
    "    plot_rewards(\n",
    "        only_incorrect_rewards_test[name],\n",
    "        title = f\"Token Position vs Reward On Test samples of {title_name} for Incorrect Samples\",\n",
    "        save_name=f\"only_line_return_test_inccorrect_samples_{title_name}_{n_samples}.html\",\n",
    "        n_samples=n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
