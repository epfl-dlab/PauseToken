{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:40:54.872840Z",
     "start_time": "2024-04-15T08:40:54.868858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")\n",
    "from evaluation.gsm8k import judge\n",
    "import json\n",
    "from thirdparty.openai.grade_school_math.dataset import read_jsonl\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdc23007fde6037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:40:54.882931Z",
     "start_time": "2024-04-15T08:40:54.875343Z"
    }
   },
   "outputs": [],
   "source": [
    "reference = read_jsonl(\"../data/gsm8k_jsonl/gsm8k/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bceb41f774e894d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:40:54.888245Z",
     "start_time": "2024-04-15T08:40:54.884464Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    texts = text.split(\"####\")\n",
    "    if len(texts) == 1:\n",
    "        return text\n",
    "    last_txt = \"#### \" + \"\".join(texts[-1].split(\" \"))\n",
    "    return \"####\".join(texts[:-1]) + last_txt\n",
    "\n",
    "\n",
    "names = os.listdir(\"./../result\")\n",
    "name2data = {}\n",
    "for name in names:\n",
    "    with open(f\"./../result/{name}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for entry in data:\n",
    "        if \"clean_output\" in entry:\n",
    "            entry[\"answer\"] = clean(entry[\"clean_output\"])\n",
    "        else:\n",
    "            entry[\"answer\"] = entry[\"output\"]\n",
    "    name2data[name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1f4b68a52acd6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:40:54.924349Z",
     "start_time": "2024-04-15T08:40:54.888958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_only_mistral.json: 0.4200151630022744, ConfidenceInterval(low=0.39423805913570886, high=0.44655041698256254), 1319 samples\n",
      "pretrain_mistral_outer_loop_3.json: 0.4071266110689917, ConfidenceInterval(low=0.38059135708870356, high=0.43442001516300227), 1319 samples\n",
      "pretrain_mistral_outer_loop_0.json: 0.3957543593631539, ConfidenceInterval(low=0.3692191053828658, high=0.42153146322971946), 1319 samples\n",
      "pretrain_mistral_outer_loop_2.json: 0.38514025777103866, ConfidenceInterval(low=0.3593631539044731, high=0.4116755117513268), 1319 samples\n",
      "mistral_v1_outputs_test.json: 0.3813495072024261, ConfidenceInterval(low=0.354814253222138, high=0.40788476118271416), 1319 samples\n",
      "mistral_v1_outputs_test_pause_token.json: 0.3639120545868082, ConfidenceInterval(low=0.3373768006065201, high=0.38968915845337376), 1319 samples\n",
      "pretrain_mistral_no_gt_outer_loop_2.json: 0.35860500379075055, ConfidenceInterval(low=0.332827899924185, high=0.38514025777103866), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_5.json: 0.35178165276724793, ConfidenceInterval(low=0.3260045489006823, high=0.37680060652009095), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_3.json: 0.3502653525398029, ConfidenceInterval(low=0.3244882486732373, high=0.37604245640636846), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_2.json: 0.34950720242608035, ConfidenceInterval(low=0.3244882486732373, high=0.37604245640636846), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_7.json: 0.34268385140257773, ConfidenceInterval(low=0.31766489764973466, high=0.3692191053828658), 1319 samples\n",
      "pretrain_mistral_outer_loop_1.json: 0.34268385140257773, ConfidenceInterval(low=0.31766489764973466, high=0.3684609552691433), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_4.json: 0.33813495072024263, ConfidenceInterval(low=0.312357846853677, high=0.3639120545868082), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_9.json: 0.33813495072024263, ConfidenceInterval(low=0.3115996967399545, high=0.3639120545868082), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_8.json: 0.33206974981046244, ConfidenceInterval(low=0.3062926459438969, high=0.35860500379075055), 1319 samples\n",
      "sft_pause_constrained_ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_0.json: 0.3282789992418499, ConfidenceInterval(low=0.30401819560272936, high=0.35405610310841545), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_6.json: 0.32676269901440486, ConfidenceInterval(low=0.3017437452615618, high=0.3525398028809704), 1319 samples\n",
      "rc_mistral_delta_reward_outer_loop_2.json: 0.32676269901440486, ConfidenceInterval(low=0.3017437452615618, high=0.35178165276724793), 1319 samples\n",
      "rc_mistral_delta_reward_outer_loop_1.json: 0.3260045489006823, ConfidenceInterval(low=0.3009855951478393, high=0.35178165276724793), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_4.json: 0.3237300985595148, ConfidenceInterval(low=0.2987111448066717, high=0.34874905231235787), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_3.json: 0.3146322971948446, ConfidenceInterval(low=0.2896133434420015, high=0.3388931008339651), 1319 samples\n",
      "wsft_pause_constrained_ll_reward_2_samps_rollout_0.json: 0.310841546626232, ConfidenceInterval(low=0.28658074298711145, high=0.3366186504927976), 1319 samples\n",
      "rc_mistral_correctness_reward_outer_loop_2.json: 0.30856709628506446, ConfidenceInterval(low=0.2835481425322214, high=0.33434420015163), 1319 samples\n",
      "rc_w_n_pauses_delta_reward_outer_loop_2.json: 0.30477634571645185, ConfidenceInterval(low=0.2805155420773313, high=0.3305534495830174), 1319 samples\n",
      "wsft_pause_constrained_ll_reward_2_samps_rollout_1.json: 0.3032600454890068, ConfidenceInterval(low=0.27824109173616374, high=0.3282789992418499), 1319 samples\n",
      "rc_mistral_correctness_reward_outer_loop_1.json: 0.29946929492039426, ConfidenceInterval(low=0.27520849128127367, high=0.3252463987869598), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_9: 0.29567854435178165, ConfidenceInterval(low=0.2714177407126611, high=0.3206974981046247), 1319 samples\n",
      "rc_w_n_pauses_delta_reward_outer_loop_1.json: 0.2926459438968916, ConfidenceInterval(low=0.26914329037149354, high=0.3169067475360121), 1319 samples\n",
      "rc_mistral_outer_loop_0.json: 0.29037149355572406, ConfidenceInterval(low=0.26611068991660347, high=0.3153904473085671), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_2.json: 0.28430629264594387, ConfidenceInterval(low=0.2608036391205459, high=0.30932524639878695), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_1.json: 0.26156178923426837, ConfidenceInterval(low=0.23805913570887036, high=0.2850644427596664), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_0.json: 0.25701288855193327, ConfidenceInterval(low=0.23426838514025777, high=0.2812736921910538), 1319 samples\n",
      "wsft_pause_constrained_ll_reward_2_samps_rollout_normal_sft_2.json: 0.25473843821076575, ConfidenceInterval(low=0.23199393479909022, high=0.2794760855636941), 1319 samples\n",
      "rc_w_n_pauses_delta_reward_outer_loop_0.json: 0.244882486732373, ConfidenceInterval(low=0.2221379833206975, high=0.26914329037149354), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_0.json: 0.2175890826383624, ConfidenceInterval(low=0.19636087945413191, high=0.2403335860500379), 1319 samples\n",
      "mistral_v1_outputs_test_pause_token_random.json: 0.21531463229719486, ConfidenceInterval(low=0.19408642911296436, high=0.23881728582259287), 1319 samples\n",
      "ll_reward_3_samps_rollout_normal_sft_include_gt_beta10_outer_loop_1.json: 0.19484457922668688, ConfidenceInterval(low=0.17437452615617893, high=0.2168309325246399), 1319 samples\n",
      "wsft_pause_constrained_ll_reward_2_samps_rollout_normal_sft_1.json: 0.17892342683851403, ConfidenceInterval(low=0.15845337376800606, high=0.2001516300227445), 1319 samples\n",
      "wsft_pause_constrained_ll_reward_4_samps_rollout_normal_sft_1.json: 0.14329037149355572, ConfidenceInterval(low=0.12509476876421532, high=0.16300227445034116), 1319 samples\n"
     ]
    }
   ],
   "source": [
    "reses = []\n",
    "for name, data in name2data.items():\n",
    "    \n",
    "    if len(data) != len(reference) or name == \"mistral_v1_outputs_train.json\":\n",
    "        continue\n",
    "    results = judge(data, reference)\n",
    "    \n",
    "    results = np.array(results).reshape((1,-1))\n",
    "    \n",
    "    ci = bootstrap(results, np.mean).confidence_interval\n",
    "        \n",
    "    reses.append((f\"{name}: {np.mean(results)}, {ci}, {len(data)} samples\", results))\n",
    "\n",
    "reses.sort(key= lambda x: x[1].mean(),reverse = True)\n",
    "for res,val in reses:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e41520d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "question:\n",
      "Carla is downloading a 200 GB file. Normally she can download 2 GB/minute, but 40% of the way through the download, Windows forces a restart to install updates, which takes 20 minutes. Then Carla has to restart the download from the beginning. How load does it take to download the file?\n",
      "####################################################################################################\n",
      "Ground Truth\n",
      "First find how many gigabytes are in 40% of the file: 200 GB * 40% = <<200*40*.01=80>>80 GB\n",
      "Then divide that number by the download rate to find the time until Windows restarts: 80 GB / 2 GB/minute = <<80/2=40>>40 minutes\n",
      "Then find the time to download the whole file after the restart: 200 GB / 2 GB/minute = <<200/2=100>>100 minutes\n",
      "Then add the time to download 40% of the file, to download the whole file, and to wait for Windows to update: 40 minutes + 100 minutes + 20 minutes = <<40+100+20=160>>160 minutes\n",
      "#### 160\n",
      "####################################################################################################\n",
      "Prediction round 1\n",
      " First, find how long the download would normally take: 200 GB * (1 minute/0.001 GB) = <<200*1024*2=409600>>409,600 minutes\n",
      "Then find how many minutes Carla has downloaded before the Windows update: 409,600 minutes * 40% = 163,840 minutes\n",
      "Then find how long the Windows update takes by subtracting the time Carla has downloaded from the total download time: 409,600 minutes - 163,840 minutes = <<409600-163840=245760>>245,760 minutes\n",
      "Then find how long Carla spends waiting for the Windows update: 20 minutes + 20 minutes/60 minutes = <<20+20/60=20>>20 minutes\n",
      "Then find how many more minutes Carla has to download by subtracting the time she spends waiting for the Windows update from the total download time: 409,600 minutes - 20 minutes = 409,580 minutes\n",
      "Then find how long the restart takes by multiplying the amount she has to download by her normal download speed: 409,580 minutes * 2 GB/minute = <<409580*2=819160>>819,160 minutes\n",
      "Then add the time Carla spends waiting for the Windows update and the time it takes her to download after the Windows reboot to find the total time it takes to download the file: 20 minutes + 819,160 minutes = 820,180 minutes\n",
      "####################################################################################################\n",
      "Clean round 1\n",
      " First, find how long the download would normally take: 200 GB * (1 minute/0.001 GB) = <<200*1024*2=409600>>409,600 minutes\n",
      "Then find how many minutes Carla has downloaded before the Windows update: 409,600 minutes * 40% = 163,840 minutes\n",
      "Then find how long the Windows update takes by subtracting the time Carla has downloaded from the total download time: 409,600 minutes - 163,840 minutes = <<409600-163840=245760>>245,760 minutes\n",
      "Then find how long Carla spends waiting for the Windows update: 20 minutes + 20 minutes/60 minutes = <<20+20/60=20>>20 minutes\n",
      "Then find how many more minutes Carla has to download by subtracting the time she spends waiting for the Windows update from the total download time: 409,600 minutes - 20 minutes = 409,580 minutes\n",
      "Then find how long the restart takes by multiplying the amount she has to download by her normal download speed: 409,580 minutes * 2 GB/minute = <<409580*2=819160>>819,160 minutes\n",
      "Then add the time Carla spends waiting for the Windows update and the time it takes her to download after the Windows reboot to find the total time it takes to download the file: 20 minutes + 819,160 minutes = 820,180 minutes\n",
      "####################################################################################################\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "name = \"pretrain_only_mistral.json\"\n",
    "name2 = \"wsft_pause_constrained_ll_reward_2_samps_rollout_0.json\"\n",
    "index = 7\n",
    "\n",
    "data = name2data[name]\n",
    "sample = name2data[name][index]\n",
    "sample2 = name2data[name2][index]\n",
    "ref_sample = reference[index]\n",
    "print(\"#\"*100)\n",
    "print(\"question:\")\n",
    "print(ref_sample[\"question\"])\n",
    "print(\"#\"*100)\n",
    "print(\"Ground Truth\")\n",
    "print(ref_sample[\"answer\"])\n",
    "print(\"#\"*100)\n",
    "print(\"Prediction round 1\")\n",
    "print(sample[\"output\"])\n",
    "print(\"#\"*100)\n",
    "print(\"Clean round 1\")\n",
    "print(sample[\"clean_output\"])\n",
    "print(\"#\"*100)\n",
    "print(judge(data, reference)[index])\n",
    "# print(\"Prediction round 0\")\n",
    "# print(sample2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09dece27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_5.json samples exculisively correct 177\n",
      "mistral_v1_outputs_test_pause_token.json samples exculisively correct 193\n"
     ]
    }
   ],
   "source": [
    "# ll_name2data = list(\n",
    "#     filter(\n",
    "#         lambda x: \"ll_reward_3_samps\" in x,\n",
    "#         name2data\n",
    "#     )\n",
    "# )\n",
    "# ll_name2data = {k: name2data[k] for k in ll_name2data}\n",
    "ll_name2data = name2data\n",
    "name1 = \"ll_reward_3_samps_rollout_normal_sft_friday_outer_loop_5.json\"\n",
    "name2 = \"mistral_v1_outputs_test_pause_token.json\"\n",
    "judge1 = judge(ll_name2data[name1], reference)\n",
    "judge2 = judge(ll_name2data[name2], reference)\n",
    "j1_c = 0\n",
    "j2_c = 0\n",
    "for index,(j1,j2) in enumerate(zip(judge1,judge2)):\n",
    "    if j1 and not j2:\n",
    "        j1_c +=1\n",
    "    if j2 and not j1:\n",
    "        j2_c += 1\n",
    "    # if j1 and not j2:\n",
    "    #     print(\"#\"*100)\n",
    "    #     print(name1, \"correct\")\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(ll_name2data[name1][index][\"output\"])\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(\"+\"*100)\n",
    "    #     print(name2, \"inccorrect\")\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(ll_name2data[name2][index][\"output\"])\n",
    "    #     print(\"-\"*100)\n",
    "    #     print(\"#\"*100)\n",
    "print(name1, \"samples exculisively correct\", j1_c)\n",
    "print(name2, \"samples exculisively correct\", j2_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb373e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf(text):\n",
    "    texts = text.split(\"####\")\n",
    "    if len(texts) == 1:\n",
    "        return text\n",
    "    last_txt = \"#### \" + \"\".join(texts[-1].split(\" \"))\n",
    "    return \"####\".join(texts[:-1]) + last_txt\n",
    "for dp in data:\n",
    "    dp[\"answer\"] = sf(dp[\"answer\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a2059b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' He produces 252 eggs x 7 days = <<252*7 =176 4 >>1764 eggs\\nThat means he sells 1764 eggs / 12 = << 1764/12=147>>147 dozen\\nHe then makes 14 7 dozen x $2/dozen = $<<1 47*2=294 >> 294 in the week\\n#### 294'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[index][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a4a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
