# @package _global_
defaults:
  - train/ppo/default
  - override /rl_algorithm/policy/model/language_model:  auto_model_for_causal_lm
  - override /rl_algorithm/policy/model/peft_config: null
  - override /rl_algorithm/policy/model/value_head: torch_transformer
  - override /callbacks/portion_annealers@trainer.trainer_callbacks: beta


run_name: "mistral_ppo_beta_curr_sft_1ep_ann_5ep"

trainer:
  trainer_callbacks:
    init_alpha: 2.0
    init_beta: 0.2
    final_alpha: 0.2
    final_beta: 2.0
    warmup_timesteps: 2
    total_timesteps: 10


rl_algorithm:
  policy:
    model:
      language_model:
        pretrained_model_name_or_path: /dlabscratch1/baldwin/pause2/PauseToken/logs/checkpoints/SFT/mistral_sft_3epochs/46c676f406cb25ae87371f2ec501182d08c7799071ecbc82a1ff4edee925babe/ckpt-12672-0.472
      value_head:
        hidden_dim: 4096

  