# @package _global_
defaults:
  - train/ppo/default
  - override /rl_algorithm/policy/model/language_model: pause_from_pretrained
  - override /rl_algorithm/policy/model/peft_config: mistral_pause #peft is already there
  - override /rl_algorithm/policy/generation/generation_config@rl_algorithm.policy.generation.train.generation_config: reasoning_step_generation
  # - override /rl_algorithm/policy/model/peft_config: null
  - override /rl_algorithm/reward: gsm8k_answer_ll
  - override /rl_algorithm/policy/model/value_head: torch_transformer

run_name: "ppo_mistral_pause_bert_reasoning_step"

rl_algorithm:
  n_envs: 16
  n_steps: 5
  batch_size: 4 # number of rollouts to be used in each training step
  n_grad_accumulation_steps: 20
  environment:
    enable_delta_reward: true
    max_actions: 5

  policy:
    model:
      language_model:
        pretrained_model_name_or_path: /dlabscratch1/baldwin/pause2/PauseToken/logs/sft/runs/2024-10-18_17-38-00/final
        post_instanciation_method_calls: [{method: attach_ctrl_token_clf}]
      value_head:
        hidden_dim: 4096