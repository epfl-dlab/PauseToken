# @package _global_

defaults:
  - train/ppo/llama1B
  - override /rl_algorithm: pretraining_value_head
  - override /rl_algorithm/policy/model/value_head: torch_transformer # mlp or torch_transformer

name: "pretraining value head"
run_name: "pretraining_value_head"

trainer:
  n_steps_before_validation: 10
  n_outer_loops: 10
  
rl_algorithm:
  n_steps: 1
  n_envs: 32 #  is the number of times rollout() is called in each outer loop, 
  batch_size: 4 # number of rollouts to be used in each training step
  ent_coef: 0
  

    # path to where the model should be saved, if null, it will be saved in /data/value_head
  saving_path: "./data/value_heads/${clean_path:${rl_algorithm.policy.model.language_model.pretrained_model_name_or_path}}_transformer.pth"

trainer:
  trainer_callbacks:
    init_portion: 1.0
    final_portion: 0.0
    warmup_timesteps: 0
    total_timesteps: 5