# @package _global_
defaults:
  - train/online_star/default
  - override /rl_algorithm/policy/model/language_model:  auto_model_for_causal_lm
  - override /rl_algorithm/policy/model/peft_config: null
  - override /trainer/callbacks/portion_annealers: linear


run_name: "LLama1B_star_baseline_3ep_sft"

trainer:
  trainer_callbacks:
    init_portion: 0.0
    final_portion: 0.0
 

rl_algorithm:
  policy:
    model:
      language_model:
        pretrained_model_name_or_path: /dlabscratch1/baldwin/pause2/PauseToken/logs/checkpoints/SFT/llama1B_sft_3epochs/313e983b5952551058e4b965ad642924c53d43634a17afd5452d91db2007cd24/ckpt-25344-0.23
      value_head:
        hidden_dim: 2048


    generation:
      train:
        generation_config:
          pad_token_id: 128002

      test:
        generation_config:
          pad_token_id: 128002